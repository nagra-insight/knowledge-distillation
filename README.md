# Ensemble and model distillation with identical deep learning models and tabular data

This work was inspired by:

- the paper ["Towards Understanding Ensemble, Knowledge Distillation, and Self-Distillation in Deep Learning"](https://www.microsoft.com/en-us/research/publication/towards-understanding-ensemble-knowledge-distillation-and-self-distillation-in-deep-learning/) 
- and its associated blog post ["Three mysteries in deep learning: Ensemble, knowledge distillation, and self-distillation"](https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/).
